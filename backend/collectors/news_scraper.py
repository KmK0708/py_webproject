"""
ë‰´ìŠ¤ í¬ë¡¤ëŸ¬
CoinDesk, CryptoNews ë“±ì—ì„œ ì•”í˜¸í™”í ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
RSS í”¼ë“œì™€ APIë¥¼ í™œìš©í•˜ì—¬ ì•ˆì •ì ìœ¼ë¡œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
"""
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import time
import re
import feedparser
import pytz

KST = pytz.timezone("Asia/Seoul")

class NewsScraper:
    """ì•”í˜¸í™”í ë‰´ìŠ¤ í¬ë¡¤ëŸ¬"""

    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        
    
    
    def to_kst(self, dt):
        if dt is None:
            return datetime.now(KST)
        if dt.tzinfo is None:
            # naive â†’ UTC ê°€ì • â†’ í•œêµ­ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
            return pytz.utc.localize(dt).astimezone(KST)
        else:
            return dt.astimezone(KST)

    def scrape_coindesk(self, limit=10):
        """
        CoinDesk RSS í”¼ë“œì—ì„œ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

        Args:
            limit (int): ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ê°œìˆ˜

        Returns:
            list: ë‰´ìŠ¤ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        news_list = []
        try:
            # CoinDesk RSS í”¼ë“œ URL
            rss_url = "https://www.coindesk.com/arc/outboundfeeds/rss/"

            feed = feedparser.parse(rss_url)

            for entry in feed.entries[:limit]:
                try:
                    title = entry.get('title', '').strip()
                    url = entry.get('link', '')

                    # ë°œí–‰ ì‹œê°„ íŒŒì‹±
                    published_at = datetime.now()
                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                        published_at = datetime(*entry.published_parsed[:6])
                    elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                        published_at = datetime(*entry.updated_parsed[:6])
                        
                    published_at = self.to_kst(published_at)

                    if title and url:
                        news_list.append({
                            'title': title,
                            'url': url,
                            'source': 'CoinDesk',
                            'published_at': published_at
                        })

                except Exception as e:
                    print(f"CoinDesk RSS í•­ëª© íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue

        except Exception as e:
            print(f"CoinDesk RSS í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")

        return news_list

    def scrape_cryptonews(self, limit=10):
        """
        CryptoNews RSS í”¼ë“œì—ì„œ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

        Args:
            limit (int): ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ê°œìˆ˜

        Returns:
            list: ë‰´ìŠ¤ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        news_list = []
        try:
            # CryptoNews RSS í”¼ë“œ
            rss_url = "https://cryptonews.com/news/feed/"

            feed = feedparser.parse(rss_url)

            for entry in feed.entries[:limit]:
                try:
                    title = entry.get('title', '').strip()
                    url = entry.get('link', '')

                    # ë°œí–‰ ì‹œê°„ íŒŒì‹±
                    published_at = datetime.now()
                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                        published_at = datetime(*entry.published_parsed[:6])
                        
                    published_at = self.to_kst(published_at)

                    if title and url:
                        news_list.append({
                            'title': title,
                            'url': url,
                            'source': 'CryptoNews',
                            'published_at': published_at
                        })

                except Exception as e:
                    print(f"CryptoNews RSS í•­ëª© íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue

        except Exception as e:
            print(f"CryptoNews RSS í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")

        return news_list

    def scrape_cointelegraph(self, limit=10):
        """
        CoinTelegraph RSS í”¼ë“œì—ì„œ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

        Args:
            limit (int): ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ê°œìˆ˜

        Returns:
            list: ë‰´ìŠ¤ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        news_list = []
        try:
            # CoinTelegraph RSS í”¼ë“œ
            rss_url = "https://cointelegraph.com/rss"

            feed = feedparser.parse(rss_url)

            for entry in feed.entries[:limit]:
                try:
                    title = entry.get('title', '').strip()
                    url = entry.get('link', '')

                    # ë°œí–‰ ì‹œê°„ íŒŒì‹±
                    published_at = datetime.now()
                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                        published_at = datetime(*entry.published_parsed[:6])
                        
                    published_at = self.to_kst(published_at)

                    if title and url and len(title) > 10:
                        news_list.append({
                            'title': title,
                            'url': url,
                            'source': 'CoinTelegraph',
                            'published_at': published_at
                        })

                except Exception as e:
                    print(f"CoinTelegraph RSS í•­ëª© íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue

        except Exception as e:
            print(f"CoinTelegraph RSS í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")

        return news_list
    
    def scrape_coinness(self, limit=10):
        """
        ì½”ì¸ë‹ˆìŠ¤ RSS í”¼ë“œì—ì„œ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

        Args:
            limit (int): ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ê°œìˆ˜

        Returns:
            list: ë‰´ìŠ¤ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        news_list = []
        try:
            # coinness RSS í”¼ë“œ URL
            rss_url = "https://www.coinness.com/rss"

            feed = feedparser.parse(rss_url)

            for entry in feed.entries[:limit]:
                try:
                    title = entry.get('title', '').strip()
                    url = entry.get('link', '')

                    # ë°œí–‰ ì‹œê°„ íŒŒì‹±
                    published_at = datetime.now()
                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                        published_at = datetime(*entry.published_parsed[:6])
                    elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                        published_at = datetime(*entry.updated_parsed[:6])
                    else:
                        published_at = datetime.utcnow()
                        
                    published_at = self.to_kst(published_at)

                    if title and url:
                        news_list.append({
                            'title': title,
                            'url': url,
                            'source': 'Coinness',
                            'published_at': published_at
                        })

                except Exception as e:
                    print(f"CoinDesk RSS í•­ëª© íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue

        except Exception as e:
            print(f"Coinness RSS í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")

        return news_list
    
    
    def scrape_tokenpost(self, limit=10):
        """
        í† í°í¬ìŠ¤íŠ¸ RSS í”¼ë“œì—ì„œ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

        Args:
            limit (int): ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ê°œìˆ˜

        Returns:
            list: ë‰´ìŠ¤ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        news_list = []
        try:
            # tokenpost RSS í”¼ë“œ URL
            rss_url = "https://www.tokenpost.kr/rss"

            feed = feedparser.parse(rss_url)

            for entry in feed.entries[:limit]:
                try:
                    title = entry.get('title', '').strip()
                    url = entry.get('link', '')

                    # ë°œí–‰ ì‹œê°„ íŒŒì‹±
                    published_at = datetime.now()
                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                        published_at = datetime(*entry.published_parsed[:6])
                    elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                        published_at = datetime(*entry.updated_parsed[:6])
                    else:
                        published_at = datetime.utcnow()
                        
                    published_at = self.to_kst(published_at)

                    if title and url:
                        news_list.append({
                            'title': title,
                            'url': url,
                            'source': 'TokenPost',
                            'published_at': published_at
                        })

                except Exception as e:
                    print(f"TokenPost RSS í•­ëª© íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue

        except Exception as e:
            print(f"CoinDesk RSS í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")

        return news_list
    

    def scrape_all_sources(self, limit_per_source=10):
        """
        ëª¨ë“  ì†ŒìŠ¤ì—ì„œ ë‰´ìŠ¤ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤.

        Args:
            limit_per_source (int): ê° ì†ŒìŠ¤ë³„ ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ê°œìˆ˜

        Returns:
            list: ëª¨ë“  ë‰´ìŠ¤ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        all_news = []

        print("ğŸ“° Coinness(í•œêµ­) í¬ë¡¤ë§ ì‹œì‘...")
        Coinness_news = self.scrape_coinness(limit=limit_per_source)
        all_news.extend(Coinness_news)
        print(f"   âœ“ Coinness: {len(Coinness_news)}ê°œ ìˆ˜ì§‘")
        
        print("ğŸ“° TokenPost(í•œêµ­) í¬ë¡¤ë§ ì‹œì‘...")
        TokenPost_news = self.scrape_tokenpost(limit=limit_per_source)
        all_news.extend(TokenPost_news)
        print(f"   âœ“ TokenPost: {len(TokenPost_news)}ê°œ ìˆ˜ì§‘")

        print("ğŸ“° CoinDesk í¬ë¡¤ë§ ì‹œì‘...")
        coindesk_news = self.scrape_coindesk(limit=limit_per_source)
        all_news.extend(coindesk_news)
        print(f"   âœ“ CoinDesk: {len(coindesk_news)}ê°œ ìˆ˜ì§‘")
        time.sleep(1)  # ìš”ì²­ ê°„ê²© ì¡°ì ˆ

        print("ğŸ“° CryptoNews í¬ë¡¤ë§ ì‹œì‘...")
        cryptonews_news = self.scrape_cryptonews(limit=limit_per_source)
        all_news.extend(cryptonews_news)
        print(f"   âœ“ CryptoNews: {len(cryptonews_news)}ê°œ ìˆ˜ì§‘")
        time.sleep(1)

        print("ğŸ“° CoinTelegraph í¬ë¡¤ë§ ì‹œì‘...")
        cointelegraph_news = self.scrape_cointelegraph(limit=limit_per_source)
        all_news.extend(cointelegraph_news)
        print(f"   âœ“ CoinTelegraph: {len(cointelegraph_news)}ê°œ ìˆ˜ì§‘")
        

        # ì¤‘ë³µ ì œê±° (URL ê¸°ì¤€)
        seen_urls = set()
        unique_news = []
        for news in all_news:
            if news['url'] not in seen_urls:
                seen_urls.add(news['url'])
                unique_news.append(news)

        # ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬ (ìµœì‹ ìˆœ)
        unique_news.sort(key=lambda x: x['published_at'], reverse=True)

        print(f"\nğŸ“Š ì´ {len(unique_news)}ê°œì˜ ê³ ìœ  ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
        return unique_news

    def extract_coin_mentions(self, title):
        """
        ë‰´ìŠ¤ ì œëª©ì—ì„œ ì–¸ê¸‰ëœ ì½”ì¸ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

        Args:
            title (str): ë‰´ìŠ¤ ì œëª©

        Returns:
            list: ì–¸ê¸‰ëœ ì½”ì¸ ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸
        """
        # ì£¼ìš” ì½”ì¸ ì‹¬ë³¼ ëª©ë¡
        major_coins = {
            'BTC': ['bitcoin', 'btc'],
            'ETH': ['ethereum', 'eth', 'ether'],
            'BNB': ['binance', 'bnb'],
            'XRP': ['ripple', 'xrp'],
            'ADA': ['cardano', 'ada'],
            'SOL': ['solana', 'sol'],
            'DOGE': ['dogecoin', 'doge'],
            'MATIC': ['polygon', 'matic'],
            'DOT': ['polkadot', 'dot'],
            'AVAX': ['avalanche', 'avax']
        }

        mentioned_coins = []
        title_lower = title.lower()

        for symbol, keywords in major_coins.items():
            for keyword in keywords:
                if keyword in title_lower:
                    mentioned_coins.append(symbol)
                    break

        return mentioned_coins


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    print("=" * 60)
    print("ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)

    scraper = NewsScraper()

    # ëª¨ë“  ì†ŒìŠ¤ì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘
    news_list = scraper.scrape_all_sources(limit_per_source=5)

    print("\n" + "=" * 60)
    print("ìˆ˜ì§‘ëœ ë‰´ìŠ¤:")
    print("=" * 60)

    for i, news in enumerate(news_list[:10], 1):
        print(f"\n[{i}] {news['source']}")
        print(f"    ì œëª©: {news['title']}")
        print(f"    URL: {news['url'][:60]}...")
        print(f"    ì‹œê°„: {news['published_at']}")

        # ì½”ì¸ ì–¸ê¸‰ ì¶”ì¶œ
        coins = scraper.extract_coin_mentions(news['title'])
        if coins:
            print(f"    ì–¸ê¸‰ëœ ì½”ì¸: {', '.join(coins)}")

    print("\n" + "=" * 60)
    print("í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 60)
